%% Intro
We now present the results related to the coverability problem on the plain \acp{PN} that we think are the most interesting.
To introduce these results, we need some additional definitions.
They will be given for plain \acp{PN}, but most of them are naturally extended to \acp{PPN}.

%% Covering set informal
Given an initialized \ac{PN} \N, the \emph{covering set} of \N is the set of markings covered by at least one reachable marking of \N.
It is an over-approximation of the reachability set that is precise enough to solve the coverability problem, and is, therefore, interesting for our study.

%% Covering set formal
\begin{defi}[Covering set]
  Let $\N = \PTm$ be an initialized \ac{PN}.
  The \emph{covering set} $S$ of \N, noted $\Cover(\N)$, is the set $\{c \mid \exists c' \in \Post^*(\N) : c \preceq c' \}$.
\end{defi}

%% Covering set picture
\begin{figure}[htbp]
  \label{fig:reach-and-cover-example}
  \centering
  \subfloat[A \ac{PN} ($|P| = 2$)]{
    \label{fig:two-net}
    \input{res/two-net}

  }

  \subfloat[The reachable markings]{
    \label{fig:two-reach}
    \input{res/two-reach}

  }\qquad
  \subfloat[The covering set]{
    \label{fig:two-cover}
    \input{res/two-cover}

  }
  \caption{Reachability and covering sets}
\end{figure}

The figure~\ref{fig:two-net} shows a marked \ac{PN} with two places.
One can therefore represents the markings as points on a plane.
The figure~\ref{fig:two-reach} shows the reachable markings in the form of an accessibility graph.
In~\ref{fig:two-cover} we see the covering set.

%% Unbounded places informal and self-covering sequence formal
Sometimes the number of tokens in a place is unbounded (\lang{c.f.} the place boundedness problem).
In a plain \ac{PN}, this is due to the existence of an increasing self-covering sequence.
\begin{defi}[Self-covering sequence]
  Given an initialized \ac{PN} $\N = \PTm$,
  a self-covering sequence is a sequence of the form:
  \(
    \mari \fire{\rho} \mar_i \fire{\sigma} \mar_j
  \),
  with $\rho$ and $\sigma$ two sequences of transitions of $T$
  and with $\mar_i \preceq \mar_j$.
\end{defi}

Note that, since $\mar_i \preceq \mar_j$, $\sigma$ is firable from $\mar_j$.
In addition, the monotonicity of \acp{PN} ensures that, with $\marp_j$ given by $\mar_j \fire{\sigma} \marp_j$, we have $\mar_j \preceq \marp_j$.
Thus, we see that it is a sufficient condition for the \emph{non-termination} of the system (the system may be able to fire transitions infinitely often).
In fact, because $\preceq$ is a well quasi-order (Lemma~\ref{lemm:wqo}), one can find in any infinite sequence $\mari \fire{} \mar_1 \fire{} \dots$ two markings $\mar_i$ and $\mar_j$ such that $\mar_i \preceq \mar_j$. \todo{take proof from mini-memoir.}
Therefore, any infinite sequence is self-covering, and the existence of such a sequence is also necessary for the non-termination of the system.

%% Increasing self-covering sequence formal
\begin{defi}[Increasing self-covering sequence]
  Given an initialized \ac{PN} $\N = \PTm$,
  an increasing self-covering sequence is a sequence of the form:
  \(
    \mari \fire{\rho} \mar_i \fire{\sigma} \mar_j
  \),
  with $\rho$ and $\sigma$ two sequences of transitions of $T$
  and with $\mar_i \prec \mar_j$.
\end{defi}

Let $Q \subseteq P$ be the set of places $Q = \{q \in P \mid \mar_i(q) < \mar_j(q)\}$.
$Q \neq \emptyset$ since $\mar_i \prec \mar_j$.

With a reasoning similar to the one above, we see that having such a sequence ensures that one can reach a marking $\marp_j$ given by $\mar_j \fire{\sigma} \marp_j$ such that $\mar_j \prec \marp_j$.
Because of the constant effect of transitions, we know that $\forall q \in Q : \mar_j(q) < \marp_j(q)$.
The unboundedness of the places in $Q$ follows.
\cite{David17} provides a complete proof.
\todo{A more formal proof that the existence of an increasing self-covering sequence is a necessary and sufficient condition for unboundedness on places is either to be done here or to be referenced.}

%% omark informal
An \omark is a way to represent a set of markings which have the same number of tokens in some places, and may have any number of tokens, potentially an infinity, in the other places.

%% omark formal
\begin{defi}[\omark]
  We define $\omega$ to be such that:
  $\omega \notin \mathbb{N}$
  and for any constant $c \in \mathbb{N}$:
  \begin{itemize}
    \item $c \leq \omega$
    \item $\omega + c = \omega$
    \item $\omega - c = \omega$
  \end{itemize}

  \emph{An \omark} \mar over a set of places $P$ is a function $\mar : P \mapsto \mathbb{N} \cup \{\omega\}$ that associates $\mar(p)$ tokens to each place $p \in P$.

  With $\mathbb{P}$ a set of parameters, $\omega \notin \mathbb{P}$,
  \emph{a parametric \omark} \mar over a set of places $P$ is a function $\mar : P \mapsto \mathbb{N} \cup \mathbb{P} \cup \{\omega\}$ that associates $\mar(p)$ tokens to each place $p \in P$.
\end{defi}

Note that an \omark \mar is a parametric \omark where $\mar(p) \in \mathbb{N} \cup \{\omega\}$ for all places $p \in P$.
Similarly, a parametric marking \mar is a parametric \omark where $\mar(p) \neq \omega$ for all places $p \in P$.
As for parametric markings, we often refer to a parametric \omark simply as \omark.

Given an \omark \mar, $\Omega(\mar) \subseteq P$ is the set of place $p$ such that $\mar(p) = \omega$, sometimes referred as \emph{\oplaces of \mar}. $P \setminus \Omega(\mar)$ is the set of \emph{\noplaces of \mar}.

%% Coverability set informal
\acp{PN} with unbounded places have an infinite reachability set.
So the covering set is also infinite.
\emph{Coverability sets} are useful to give a finite representation of the covering set thanks to \omark.
%%
In order to define them formally, we need to know about the maximal markings and the upward and downward closure of a set of markings.

%% Max markings informal
The maximal elements of a set are the markings that are not covered by any other marking of the set.
%% Max markings formal
\begin{defi}[Maximal markings]
  Given a set of markings $S$, the set of maximal elements of $S$ is
  $\Max(S) = \{ \mar \in S \mid \nexists \marp \in S \text{ s.t. } \mar \prec \marp \}$.
\end{defi}

%% Closure formal
\begin{defi}[Upward- and downward-closure on markings]
  Let $S \subseteq \mathbb{N}^{|P|}$ be a set of markings on the places $P$:
  \begin{itemize}
    \item The \emph{upward-closure} of $S$, noted $\upc(S)$, is the set
      $\{\mar \in \mathbb{N}^{|P|} \mid \exists \marp \in S : \marp \preceq \mar\}$,
    \item The \emph{downward-closure} of $S$, noted $\downc(S)$, is the set
      $\{\mar \in \mathbb{N}^{|P|} \mid \exists \marp \in S : \mar \preceq \marp\}$.
  \end{itemize}
  The closure of a marking \mar is the closure of the singleton $\{\mar\}$.
\end{defi}

%% Up closure example
For instance, with $\mar = (1, 2, 3)$, we have that its upward-closure is $\upc(\mar) = \{(i, j, k) \mid i \geq 1, j \geq 2, k \geq 3\}$.

%% Closed set formal
\begin{defi}[Upward- and downward-closed set of markings]
  A set $S$ of markings is said \emph{upward-closed} if $S = \upc(S)$.
  It is said \emph{downward-closed} if $S = \downc(S)$.
\end{defi}

%% Coverability set formal
\begin{defi}[Coverability set \citep{Finkel87,Finkel90}]
  Given an initialized \ac{PN} $\N = \PTm$, a \emph{coverability set} $S$ of \N is a set of markings such that $\downc(S) = \downc(\Post^*(\mari))$.
\end{defi}

%% Usefulness of coverability sets and omarks
Notice that, since $\downc(\mar)$ exists and is unique for all \omark \mar, an \omark may always stands for one and only one downward closed set.
Symmetrically, it is known that any downward closed set may be represented by a finite set of \omarks \citep{Geeraerts06}. \todo{Indeed...}

In particular, finite coverability sets may effectively represent, thanks to \omarks, any covering set:
Having an \omark \mar in a coverability set $S$ of $\N$ denotes that for all marking $\mar_1$ such that $\mar_1(p) = \mar(p) \forall p \in \{p \mid \mar(p) \neq \omega\}$, there exists a marking $\mar_2$ in the reachability set of \N such that $\mar_1 \prec \mar_2$.
\todo{We prove it by giving a minimal coverability set for any covering set.}

%% Max markings and minimal coverability set informal.
Indeed, the set of maximal reachable markings of \N exists, is finite and forms a minimal coverability set.

%% Max markings and minimal coverability set formal.
\[\downc(\Max(\Post^*(\mari))) = \downc(\Post^*(\mari))\]
\[\forall S \text{ such that } \downc(S) = \downc(\Post^*(\mari))\text{, we have } |S| \geq |\Max(\Post^*(\mari))|\]

Moreover, for any set of markings $S$ over a finite set of places $P$, the set of maximal markings of $S$ exists, is finite and is such that $\downc(\Max(S)) = \downc(S)$.

\todo{Lemme: For any downward-closed set S of markings, the downward-closure of the set of maximal markings of S is S}

\todo{Proof: the existence of a finite set of maximal elements}
It is straightforward to extend the proof to any downward-closed set.

%% coverability problem 2 formal
It is worth noticing that, in the context of \acp{PN}, the coverability problem for a set of markings $S$ may be defined as follows:
\begin{defi}[Coverability problem]
  \label{defi:upclocovprblm}
  Given a \ac{PN} \N and an upward-closed set $U = \upc(S)$ of markings of \N, determine whether $\Post^*(\mari) \cap U = \emptyset$.
\end{defi}

An upward closed set is always infinite.
It can be effectively represented through its unique set of minimal elements whose it is the upward closure:
\begin{lemm}
  For all upward-closed set $U \subseteq \mathbb{N}^{|P|}$, its set of minimal element $\Min(U) = \{\mar \in U \mid \nexists \marp \in U : \marp \prec \mar\}$ is such that $\upc(\Min(U)) = U$.
\end{lemm}

The following lemma ensure that this set is finite:
\begin{lemm}[Dickson's lemma]
  For all $c \in \mathbb{N}$, every set of $c$-tuples of natural numbers have finitely many minimal elements.
\end{lemm}
This result may easily be extended to $c$-tuples of values from any ordered countable set.

Moreover, this representation is effective in the sense that the set may be manipulated through it.
\cite{Ganty09} gives a way to perform the operations on upward closed sets through their minimal elements.

\subsection{A general backward algorithm $\back$}
\label{sec:backward-algorithm}

There exists a simple way to solve the coverability problem for all the examples of \acp{WSTS} above mentioned.
This algorithm was introduced by Abdulla \lang{et al.} \citep{Abdulla96}.
It is close of the one introduced earlier in \cite{Finkel90}.
%Even if we do not see how to use it in the context of \ac{PPN}, we mention it here because it helps to grasp, by comparison with the Karp and Miller algorithm presented in the following section, where does lie the difficulties of the coverability problem.

Relying on the definition~\ref{defi:upclocovprblm} of the coverability problem, given an upward-closed set of markings $U$, the algorithm computes $\Pre^*(U)$ by iterating the $\Pre$ operator.
\todo{The termination and correction of the algorithm were proven in cite{Abdulla96}. (check it)}
The termination is ensured by the existence of a fixed point in the sequence of upward closed set of markings $(R_i)_{i \geq 0}$:
\begin{gather*}
  R_0 = U \\
  \forall i > 0 : R_i = R_{i-1} \cup \Pre(R_{i-1})
\end{gather*}
When this fixed point is reached, we have $\Pre^*(U)$.
If $\mari \in \Pre^*(U)$, one can conclude positively.
Otherwise, the result is negative.
We call this algorithm $\back$.

This approach is elegant and general, but often inefficient in practice.
It is well-known that a forward exploration of the state of space (\lang{i.e.}, in this context, using $\Post$ instead of $\Pre$) is usually more efficient \citep{Henzinger98}.
We now present a forward algorithm, but whose the application is restricted to \ac{PN}.

\subsection{The Karp and Miller algorithm}

Although it was not originally designed for this purpose, the Karp and Miller algorithm \cite{Karp69} is a classical algorithm to compute a coverability set of an initialized \ac{PN}.
More precisely, it constructs a coverability tree and uses an acceleration function to systematically detect self-covering sequences, and thus ensures the termination.

\begin{defi}[Coverability tree]
  Given a \ac{PN} $\N = \PTm$, a coverability tree $\mathcal{T}$ of \N is a labelled tree $\mathcal{T} = \langle N, B, n_0, \Lambda\rangle$ where:
  \begin{itemize}
    \item $N$ is the set of nodes of the tree.%, is a set of \omark of \N such that $\downc(N) = \Cover(\N)$.
    \item $n_0 \in N$ is the root of the tree, \lang{i.e.} $\nexists n \in N$ such that $(n, n_0) \in B$.
    \item $\Lambda : N \mapsto (\mathbb{N} \cup \{\omega\})^{|P|}$ is a labelling function that associate to each node an \omark of \N.
    \item $B \subseteq N \times N$, the set of edges, is such that:
      \begin{itemize}
        \item with $(n_1, n_2) \in N^2$, if there exists an edge $(n_1, n_2) \in B$ then there exists a sequence $\sigma$ of transitions of $T$ such that $\Lambda(n_1) \fire{\sigma} \Lambda(n_2)$,
        \item for all node $n \in N \setminus \{n_0\}$, there exists a path from the root to $n$, that is, there exists a sequence of edges of $B$ of the form $((n_0, n_1), (n_1, n_2), \dots, (n_{i}, n))$, $i \geq 1$, and
        \item there are no cycles, that is, there are no sequences of edges of $B$ of the form $((n_1, n_2), (n_2, n_3), \dots, (n_i, n_1))$.
      \end{itemize}
  \end{itemize}
  and such that $\downc(\{\Lambda(n) \mid n \in N\}) = \Cover(\N)$.
\end{defi}

We denote by $\treepath{n}$ the path in the tree from the root to $n$, that is the sequence of nodes from $n_0$ to $n$.
$\treepath{n}$ is called \emph{the branch to $n$} and the nodes of $\treepath{n}$ are the \emph{ancestors} of $n$.
With $m \in \treepath{n}$, $\treepath{m,n}$ is the sequence of nodes from $m$ to $n$.
If $m \notin \treepath{n}$, $\treepath{m,n}$ is the empty sequence.
%$\treepath{n}$ is the sequence of nodes from the path, $\treepathe{n}$ is the sequence of edges.

To keep $N$ finite, the Karp and Miller algorithm exploits the strong monotonicity of \acp{PN} to introduce \omark{}s through an \emph{acceleration function} $\KMAcc$.
This function takes a marking \mar to accelerate and a set of markings $S$ as a base for the acceleration and returns a marking $\mar_\omega$ such that:
\[
  \mar_\omega(p) =
  \begin{cases}
    \omega    &\text{if } \exists \marp \in S : \marp \prec \mar \text{ and } \marp(p) < \mar(p) \\
    \mar(p)  &\text{otherwise}
  \end{cases}
\]

The acceleration function is said to accelerate a marking if the first case holds for one or more place.
These places are said \emph{accelerated}.


The algorithm constructs the tree $\mathcal{T}$ as follows:
The root $n_0$ of the tree is labelled with \mari.
A frontier $F$ is defined to be the set of unprocessed nodes of the tree and is initialised to $\{n_0\}$.
Then, while $F$ is non-empty, a node $n$ is chosen from $F$ to be processed:
(1) it is removed from $F$, and (2) if there is no node $n'$ in $\mathscr{T}_n$ such that $\Lambda(n) = \Lambda(n')$, then for all \omark $\mar \in \Post(\Lambda(n))$, (2.1) a node labelled with $\KMAcc(\mar, \mathscr{T}_n)$ is added to the frontier and (2.2) to the tree as a child of $n$.

The correctness and the termination of the algorithm lies on the strong monotonicity of \acp{PN}, and was proved by Karp and Miller in their work \cite{Karp69}.

To prove that the Karp and Miller Tree $\mathcal T$ is a coverability tree of \N, we show:
\begin{enumerate}
  \item \todo{} that one can construct a sequence from \mari to any marking \mar “covered by the tree”, given a node $n$ such that $\mar \in \downc(\Lambda(n))$, and
  \item \todo{} that any marking $\mar \in \Post^*(\mari)$ is “covered by at least one node of the tree”.
\end{enumerate}

\todo{} Finally, we prove that $\mathcal{T}$ is finite and that the algorithm terminates.

Although very different in form, the proofs are based on those stated in \cite{Karp69}.

\begin{lemm}
  Given an initialized \ac{PN} $\N = \PTm$ and a node $n$ of its Karp and Miller tree $\mathcal{T} = \langle N, B, n_0, \Lambda\rangle$,
  for any marking $\mar \in \downc(\Lambda(n))$ there exists a sequence of transitions $\sigma \in T^*$ and a marking $\marp$ such that $\mari \fire{\sigma} \marp$ and $\mar \preceq \marp$.
\end{lemm}

\begin{proof}
  We show that there exists a function $\Sigma : \mathbb{N}^{|P|} \times N \mapsto T^* : \mar, n \rightarrow \sigma$ that, given a marking $\mar$ and a node $n$ such that $\mar \in \downc(\Lambda(n))$, gives such a sequence $\sigma$.

  For this purpose, we introduce some notations:
  \begin{itemize}
    \item we attach to the Karp and Miller tree $\mathcal{T}$ the mapping $\lambda : N \setminus \{n_0\} \mapsto T$ that gives for all node of the tree (but the root) the transition used to create it at step (2) of the Karp and Miller algorithm.

      By abuse of notation, we will note $\lambda((n_1, n_2, ..., n_m))$
      %with $n_i, i \in \{1, ..., m\}$ some nodes of $\mathcal{T}$
      with  $n_i \in N$
      the sequence $(\lambda(n_2), ..., \lambda(n_m))$.
    \item for any $n \in N \setminus \{n_0\}$, $\parent{n}$ is the direct ancestor, or \emph{parent}, of $n$ in $\mathcal{T}$, that is, the last but one node in $\treepath{n}$.
    \item \removed{given a sequence of nodes, for any node $n$ of the sequence but the last one, $\child{n}$ is the next node in the sequence.}
    \item \todo{introduce operations on sequences: k.s, s1+s2}
  \end{itemize}

  Before we look at $\Sigma$, here is one key observation on the Karp and Miller tree:
  since the Karp and Miller algorithm never remove $\omega$s, we have
  $\Omega(\Lambda(\parent{n})) \subseteq \Omega(\Lambda(n))$.

  Without loss of generality, we assume that $\mari$ does not map any place to $\omega$, and thus $\Sigma(\mar, n_0) = ()$.

  We now recursively show that $\Sigma(\mar, n)$ exists for all such $\mar, n$ pair where $n \neq n_0$.

  So assume $\mar$ and $n$ given and $\mar \in \downc(\Lambda(n))$.
  When we deal with a given node, we'll need a specific order on the places, so we adopt the following conventions:
  \begin{itemize}
    \item with $p_i \in \Omega(\Lambda(n))$,
      \begin{itemize}
        \item $n^\omega_i$ denotes the first node of $\treepath{n}$ such that $\Lambda(n_i) = \omega$, and
        \item $n_i$ denotes the node used by $\KMAcc$ to accelerate $p_i$ in $\Lambda(n^\omega_i)$, \lang{i.e.}, \todo{the last} node of $\treepath{n^\omega_i}$ such that $\Lambda(n_i) \preceq \Lambda(n^\omega_i)$.
      \end{itemize}
    \item with $i$ and $j \in \{1, …, |P|\}$, we have:
      \begin{itemize}
        \item $i < j$ whenever $p_i \in \Omega(\Lambda(n)) \wedge p_j \notin \Omega(\Lambda(n))$:
          the \oplaces are before the \noplaces,
        \item $i < j$ whenever $p_i$ and $p_j \in \Omega(\Lambda(n))$ and $\treepath{n^\omega_i}$ is a prefix of $\treepath{n^\omega_j}$:
          the places accelerated first come first,
        \item $i < j$ whenever $p_i$ and $p_j \in \Omega(\Lambda(n))$, $n^\omega_i = n^\omega_j$ and $\treepath{n_i}$ is a prefix of $\treepath{n_j}$:
          the places accelerated thanks to nodes nearer of the root come first,
        \item otherwise, the order between $i$ and $j$ may be fixed arbitrarily.
      \end{itemize}
    \item $\zeta(n) = \{1, ..., I\}$ is the possibly empty set of the indices of the places that were accelerated ``before'' $n$: $i \in \zeta(n)$ iff $p_i \in \Omega(\Lambda(\parent{n}))$,
    \item $\alpha(n) = \{I+1, ..., J\}$ is the possibly empty set of the indices of the places accelerated ``at'' $n$: $j \in \alpha(n)$ iff $p_j \in \Omega(\Lambda(n))$ and $p_j \notin \Omega(\Lambda(\parent{n}))$.
  \end{itemize}

  The idea of the construction of $\Sigma(\mar, n)$ is that for any \oplace $p_i$ of $\Lambda(n)$, one can extract from $\treepath{n}$ a self-covering sequence $\sigma_i$ strictly increasing in $p_i$:
  $\Effect(\sigma_i)(p_i) > 0$ and $\Effect(\sigma_i)(p) \geq 0$ for all $p \in P$.

  As base case, consider that $\zeta(n) = \emptyset$.
  If $\alpha(n) = \emptyset$, there was no acceleration on $\treepath{n}$ and by construction of $\mathcal{T}$, $\mari \fire{\lambda(\treepath{n})} \Lambda(n)$.
  So we define $\Sigma(\mar, n)$ to be $\lambda(\treepath{n})$ whenever $\zeta(n) = \emptyset$ and $\alpha(n) = \emptyset$.\\
  Actually this is a special case of the one where $\alpha(n)$ may be not empty.
  In that case, \marpp given by $\mari \fire{\lambda(\treepath{n})} \marpp$ agrees with $\Lambda(n)$ in its \noplaces.
  To reach \marp that covers \mar in all its places, we explicitly repeat the increasing self-covering sequences implicitly detected by the Karp and Miller algorithm.
  By construction of $\mathcal{T}$ we know that for all $j \in \alpha(n) = \{1, ..., J\}$, $\Lambda(n_j) \prec \marpp$.
  Therefore:
  \begin{itemize}
    \item $\lambda(\treepath{n_j,n^\omega_j})$ is enabled in \marpp,
    \item $\Effect(\lambda(\treepath{n_j,n^\omega_j}))(p) \geq 0$ for all $p \in P$, and
    \item $\Effect(\lambda(\treepath{n_j,n^\omega_j}))(p_j) > 0$ for all $j \in \alpha(n)$.
  \end{itemize}
  Note that $n^\omega_j = n$.
  Thus, for all such $j$, $\treepath{n_j,n^\omega_j}$ is the increasing self-covering sequence we were looking for.
  Moreover, % whenever $\zeta(n) = \emptyset$,
  $\sigma_j = \lambda(\treepath{n_j,n})$ for all $j \in \alpha(n)$
  and
  there exists some naturals $k_j$ such that we can define $\Sigma(\mar, n)$ to be
  \[ \lambda(\treepath{n}) + k_1 \cdot \sigma_1 + \dots + k_J \cdot \sigma_J \] 
  Actually, one can easily compute such $k_j$ to obtain the shortest sequence of this form.
  With $s_j = \lambda(\treepath{n}) + k_1 \cdot \sigma_1 + … + k_j \cdot \sigma_j$, we have:
  \[
    k_j =
    \begin{cases}
      \left\lceil
        \frac{\mar(p_j) - \mari(p_j) - \Effect(\lambda(\treepath{n}))(p_j)}
            {\Effect(\lambda(\treepath{n_j,n}))}
      \right\rceil
      &\text{ if } j = 1\\
      \\
      \max\left(0,
        \left\lceil
          \frac{\mar(p_j) - \mari(p_j) - \Effect(s_{j-1})(p_j)}
              {\Effect(\lambda(\treepath{n_j,n}))}
        \right\rceil
      \right)
      &\text{ if } j \in \{2, ..., J\}
    \end{cases}
  \]

  The chosen order ensure that with $j_1 \leq j_2$ we have $|\sigma_{j_1}| \geq |\sigma_{j_2}|$ and so any other order would give a sequence longer or as long as the one computed here.


  The induction step considers the case where $\zeta(n) \neq \emptyset$.
  By definition, a node in this case have at least one ancestor lying in the base case.
  Once again, let us focus first on the simpler case where $\alpha(n) = \emptyset$.
  Here one can easily compute the $\preceq$-lowest marking \marpp of $\downc(\Lambda(\parent{n}))$ such that $\marpp \fire{\lambda(n)} \marp$ (with $\mar \preceq \marp$) and that agrees with $\Lambda(\parent{n})$ for its \noplaces. It is given by:
  \[
    \marpp(p) = \begin{cases}
      \Lambda(\parent{n})(p)
        &\text{ if } p \notin \Omega(\Lambda(\parent{n})) \\
      \max(\mar(p) - \Effect(\lambda(n))(p), I_{\lambda(n)}(p))
        &\text{ otherwise}
    \end{cases}
  \]

  Indeed, %(1)
  $\lambda(n)$ is enabled in $\marpp$:
  for the \noplaces $p$ of $\Lambda(\parent{n})$, the Karp and Miller algorithm ensures that $I_{\lambda(t)}(p) \leq \marpp(p)$;
  and for the \oplaces $p$ of $\Lambda(\parent{n})$, the chosen value is at least $I_{\lambda(t)}(p)$.\\
  Moreover, %(2)
  $\mar \preceq \marp$:
  for the \noplaces $p$ of $\Lambda(\parent{n})$, we have $\marp(p) = \marpp(p) + \Effect(\lambda(n))(p) = \Lambda(n)(p) \geq \mar(p)$ by choice of $n$ and \mar;
  and for the \oplaces $p$ of $\Lambda(\parent{n})$, we have $\marp(p) = \marpp(p) + \Effect(\lambda(n))(p) \geq \mar(p)$ by construction of $\marpp$.\\
  Thus, we define
  $\Sigma(n, \mar)$ to be $\Sigma(\parent{n}, \marpp) + \lambda(n)$
  whenever
  $\alpha(n) = \emptyset \wedge \zeta(n) \neq \emptyset$.

  In the general case, $\alpha(n)$ may be not empty.
  There a difficulty arises from the fact that $\lambda(\treepath{n_j,n^\omega_j}), j \in \alpha(n)$ may not be a self-covering sequence since its effect may be negative for some places $p_i$ (with $i \in \zeta(n)$).
  This difficulty is solved by integrating enough repetitions of $\sigma_i$ along with $\lambda(\treepath{n_j,n^\omega_j})$ in $\sigma_j$ to counterbalance it.

  Here are two ways to shows that it can be done.
  First, it may be easier to convince oneself of this by noting that, for all such $i$, there is a marking \marpp such that $\Sigma(\marpp, n^\omega_i)$ has enough tokens in $p_i$ to undo the negative effect of $\lambda(\treepath{n_j,n^\omega_j})$ in this place. But the calculation of \marpp is a little technical.\\
   However, the computation of an actual self-covering sequence increasing in $p_j$, to use instead of $\treepath{n_j, n^\omega_j}$, is easy. With only one $i$, it is given by:
   \[
     s_{j,i} = \lambda\left(\treepath{n_j,n_i} + l_{j,i} \cdot \treepath{n_i,n^\omega_i} + \treepath{n^\omega_i,n^\omega_j}\right)
    \text{ with } l_{j,i} =
    \left\lceil \frac{-\Effect(\lambda(\treepath{n_j,n^\omega_j}))(p_i)}
                     { \Effect(\lambda(\treepath{n_i,n^\omega_i}))(p_i)} \right\rceil \text{.}\]

  In the case where there are several different $i$'s, the sequence can be obtained by considering the $i$'s one by one. Then, the sequence we are looking for is $\lambda\left(s_{j,I}\right)$ given by: $\forall i \in \{0\} \cup \zeta(n) = \{0, ..., I\}$
  \[
    s_{j,i} =
    \begin{cases}
      s_{j,0} = \treepath{n_j,n^\omega_j}
        &\text{ if } i = 0 \\
      s_{j,i} = s_{j,i-1}
        &\text{ if } i > 0 \text{ and } \Effect(\lambda\left(s_{j,i-1}\right))(p_i) \geq 0 \\
      s_{j,i} = \text{ début de } s_{j,i-1} \text{ puis } l_{j,i} \cdot \treepath{n_i,n^\omega_i} \text{ puis fin de } s_{j,i-1}
        &\text{ otherwise}
    \end{cases}
  \]
  \todo{refaire les notations}
  with
  \[
    l_{j,i} = 
    \left\lceil \frac{-\Effect(\lambda(s_{j,i-1}))(p_i)}
                     { \Effect(\lambda(\treepath{n_i,n^\omega_i})(p_i)} \right\rceil \text{.}
  \]

  This provides us with a mean to compute an actual increasing self-covering sequence for every accelerated place $p_j, j \in \alpha(n)$.

  The computation of the value of each $l_{j,i}$ is then done in a similar way to that of the $k_j$ mentioned above.

  Indeed, consider that the first accelerated place $p_j$ is such that $\Effect(\lambda(\treepath{n_j,n^\omega_j}))(p_i)$ is negative for some $p_i$.



  Formally, for all $i \in \zeta(n)$ and $j \in \alpha(n), i < j$, there exists some naturals $l_{j,i}$ such that the sequence
  $\sigma_j = $\todo{See notes "rep3" pour les détails}
  %$\sigma_j = l_{j,1} \cdot \sigma_1 + … + l_{j,I} \cdot \sigma_I + \lambda(\treepath{n^\omega_I,n})$
  is self-covering and strictly increasing in $p_j$.
 
  \todo{Note: dans ce cas, choisir un ordre différent peut donner une séquence plus courte.}
  \todo{Donc Sigma(m,n) = see notes "rep3"}
%
%
% 
%
%
%
%
%  Let $i$ and $j \in \{1, …, |P|\}$ be such that:
%  Let 
%  \begin{itemize}
%    \item $i < j$ whenever $\Lambda(n)$
%  \end{itemize}
%
%  For any node $n \in N$ let $\zeta(n) = \Omega(\Lambda(\parent{n}))$ be the set of \oplaces that were already accelerated in $\Lambda(\parent{n})$, and
%
%
%
%  Thus we have for any node $n \in N$ three disjoint sets of places whose the union is $P$:
%  \begin{itemize}
%    \item $\eta(n) = P \setminus \Omega(\Lambda(n))$ are the \noplaces of $\Lambda(n)$,
%    \item $\zeta(n) = \Omega(\Lambda(\parent{n}))$ are the \oplaces that were already accelerated in $\Lambda(\parent{n})$, and
%    \item $\alpha(n) = \Omega(\Lambda(n)) \setminus \Omega(\Lambda(\parent{n}))$ are the newly accelerated places.
%  \end{itemize}
%
%
%
%  If $n$ is the root of the Karp and Miller tree, \mar is covered by $\Lambda(n_0)$ and thus $\Sigma(n, \mar)$ is the empty sequence:
%  \( \Sigma(n, \mar) = () \text{ whenever } n = n_0 \).
%  This is the base case.
%
%  If $n \neq n_0$, we have $\Sigma(n, \mar) = \Sigma(\parent{n}, \marpp) + \lambda(n) + \lambda(s_I)$ for well chosen marking $\marpp \in \downc(\Lambda(\parent{n}))$ and sequence of nodes $s_I$.
%
%
%
%
%
%
%
%
%
%
%
%
%
%  We now present several simple cases for the induction step in order to easily introduce the general case.
%
%  If $\Lambda(n)$ does not map any place to $\omega$, then,
%  none of $\left\{\Lambda(n') \mid n' \in \treepath{n}\right\}$ do
%  (since the Karp and Miller algorithm never removes $\omega$s)
%  and \mar is covered by $\Lambda(n)$.
%  Thus, the sequence comes directly from $\treepath{n}$.
%  \( \Sigma(n, \mar) = \lambda(\treepath{n}) \text{ whenever } \Omega(\Lambda(n)) = \emptyset \).
%  %Note that the previous case is a special case of this one.
%  In a recursive way, this can be expressed as follows: $\Sigma(n, \mar) = \Sigma(\parent{n}, \Lambda(\parent{n})) + \lambda(n) \text{ whenever } \Omega(\Lambda(n)) = \emptyset$.
%  %\( \Sigma(n, \mar) = \lambda(\treepath{n}) \text{ whenever } \nexists p \in P \text{ s.t. } \Lambda(n)(p) = \omega \)
%  %\[ \Sigma(n, \mar) = \Sigma\big(P(n),\Lambda(P(n))\big) + (\lambda(n)) = \lambda(\treepath{n}) \text{ whenever } \nexists p \in P \text{ s.t. } \Lambda(n)(p) = \omega \]
%
%  If $n$ is the first node of the branch labelled with a marking with places mapped to $\omega$,
%  that is $\zeta(n) = \emptyset \wedge \alpha(n) \neq \emptyset$,
%  we construct $\Sigma(n, \mar) = \sigma$ as follows.
%  (Here are the ideas, we express them more precisely and in a recursive way right after.)\\
%  First, consider the case where there exists exactly one \oplace $p$ in $\Lambda(n)$.
%  This $\omega$ was introduced by $\KMAcc$ thanks to a node $n' \in \treepath{n}, \Lambda(n') \prec \Lambda(n)$.
%  Thus $\lambda(\treepath{n',n})$ is an increasing self covering sequence
%  and
%  there exists some $k \in \mathbb{N}$ and $\marp \in \mathbb{N}^{|P|}$, $\mar \preceq \marp$
%  such that
%  $\sigma = \lambda(\treepath{n'}) + k \cdot \lambda(\treepath{n',n})$ and $\mari \fire{\sigma} \marp$. % with $\mar \preceq \marp$.
%  More precisely, one can choose any $k$ that verifies $k \geq \left\lceil\frac{\mar(p) - \Lambda(n')(p)}{\Effect(\lambda(\treepath{n',n}))}\right\rceil$. %, but lower $k$ may also exists \todo{see notes +1+}.
%  Note that $k > 0$.\\
%  Second, if there exists many \oplaces $p_i$ in $\Lambda(n)$, one can compute $\sigma$ by considering the different $p_i$ one by one:
%  We obtain for $p_1$ the sequence $\sigma_1 = \lambda(\treepath{n_1'}) + k_1 \cdot \lambda(\treepath{n_1',n})$ as above.
%  Let $s_i$ be the sequence of nodes used to obtain $\sigma_i$, that is $s_1 = \treepath{n_1'} + k_1 \cdot \treepath{n_1',n}$.
%  Now observe that
%  the second $\omega$ was introduced thanks to a node $n_2$ that may appear many times in $s_1$ (it does whenever $n_2 \in \treepath{n_1',n}$ and $k_1 > 1$).
%  This recursively extends to any $i \geq 2$.
%  So, the construction of $\sigma_i$ is the same that for $\sigma_1$ except that we use $s_{i-1}$ instead of $\treepath{n}$ and that if $n_i'$ appears many times in $s_{i-1}$, we consider one of its occurrence. Note that the last one should produce the shortest sequence.%whenever there is many $n_i'$ in $\sigma_{i-1}$ we consider the last one of $\sigma_i$.
%  \todo{illustration}
%
%  Let us now express this in a more formal and recursive way.\\
%  Since $\zeta(n) = \emptyset$, the previous case give us $\Sigma(\parent{n}, \Lambda(\parent{n}))$.
%  We denote by $s_0$ the sequence of nodes used to obtain $\Sigma(\parent{n}, \Lambda(\parent{n}))$.
%  Here this sequence is $\treepath{\parent{n}}$, but for the cases that follow, let's keep in mind that $s_0$ is the sequence of nodes used to obtain $\Sigma(\parent{n}, \mathit{previous\_marking})$, whatever $\mathit{previous\_marking}$ is.\\
%  Each place $p_i, i \in \{1, 2, ..., I\}$ of $\alpha(n)$ is accelerated thanks to a node $n_i$.
%  We give an order on this places such that, for $i \leq j$, $\treepath{n_i}$ is shorter or as long as $\treepath{n_j}$.
%  This is to consider the longest self increasing covering sequences first and thus obtain the shortest sequence $\sigma$ \todo{to prove}.\\
%  We compute the sequence of nodes $s$ such that $\sigma = \lambda(s) = \lambda(s_0 + (n) + s_I)$.
%  $s_0 + (n)$ is the ``simple way'' to reach a marking $\downc(\Lambda(n))$ and whose the \noplaces have the values of those of $\Lambda(n)$.
%  We compute shortest $s_I$ to have \marp, $\mar \preceq \marp$:
%  \[
%    s_i =
%    \begin{cases}
%      \left\lceil
%        \frac{\mar(p_i) - \mari(p_i) - \Effect(\lambda(s_0+(n)))(p_i)}
%            {\Effect(\lambda(\treepath{n_i,n}))}
%      \right\rceil
%      \cdot \treepath{n_i,n}
%      &\text{ if } i = 1\\
%      \\
%      \max\left(0,
%        \left\lceil
%          \frac{\mar(p_i) - \mari(p_i) - \Effect(\lambda(s_0+(n)+s_{i-1}))(p_i)}
%              {\Effect(\lambda(\treepath{n_i,n}))}
%        \right\rceil
%      \right)
%      \cdot \treepath{n_i,n}
%      &\text{ if } i \in \{2, ..., I\}\\
%    \end{cases}
%  \]
%
%So we have $\Sigma(n, \mar) = \Sigma(\parent{n}, \Lambda(\parent{n})) + \lambda((n) + s_I)$ whenever $\zeta(n) = \emptyset \wedge \alpha(n) \neq \emptyset$.
%
%  %Since the sequences $s_i$ thus obtained begin with $\treepath{n}$, $\Sigma(n , \mar)$ can be expressed in a recursive form, but it is more complicated than necessary to prove its existence.
%  %\todo{see notes +1+}
%
%
%
%
%  If $\Lambda(n)$ was not accelerated but some of its ancestors was (that is:
%  %$\exists p \in P : \Lambda(n)(p) = \omega$ and $\nexists p' \in P \text{ such that } \Lambda(n)(p') = \omega \wedge \nexists n' \in \treepath{n}, n' \neq n, \Lambda(n')(p') = \omega$.
%  %$\exists p \in P \text{ such that } \Lambda(n)(p) = \omega$ and for all such $p$, $\exists n' \in \treepath{n}, n' \neq n, \Lambda(n')(p) = \omega$)
%  $\alpha(n) = \emptyset \wedge \zeta(n) \neq \emptyset$)
%  then
%  %since the Karp and Miller algorithm never removes $\omega$s,
%  we know that its parent $\parent{n}$ is labelled with a marking ``having all the $\omega$s'' of $\Lambda(n)$:
%  $\Omega(\Lambda(n)) = \Omega(\Lambda(\parent{n}))$.\\
%  One can easily compute the lowest marking $\marpp$ in $\downc(\Lambda(\parent{n}))$ such that $\marpp \fire{\lambda(n)} \marp$ with $\mar \preceq \marpp$:
%  \[
%    \marpp(p) = \begin{cases}
%      \Lambda(\parent{n})(p)
%        &\text{ if } p \notin \Omega(\Lambda(\parent{n})) \\
%      \max(\mar(p) - \Effect(\lambda(n))(p), I_{\lambda(t)}(p))
%        &\text{ otherwise}
%    \end{cases}
%  \]
%
%  %We show that there exists a marking $\marpp \in \downc(\Lambda(\parent{n}))$ such that
%  %(1) $\lambda(n)$ is enabled in $\marpp$
%  %and that
%  %(2) $\marp$ given by $\marpp\fire{\lambda(n)}\marp$ is such that $\mar \preceq \marp$.\\
%  %To define \marpp we use $\Lambda(\parent{n})$ and choose some values for the \oplaces:
%  %We claim that any \marpp as follows holds.
%  %\[
%  %  \marpp(p) = \begin{cases}
%  %    \Lambda(\parent{n})(p)
%  %      &\text{ if } p \notin \Omega(\Lambda(\parent{n})) \\
%  %    c \text{ with } c \geq \max(\mar(p) - \Effect(\lambda(n))(p), I_{\lambda(t)}(p))
%  %      &\text{ otherwise}
%  %  \end{cases}
%  %\]
%  Indeed, %(1)
%  $\lambda(n)$ is enabled in $\marpp$:
%  for the \noplaces $p$ of $\Lambda(\parent{n})$, the Karp and Miller algorithm ensures that $I_{\lambda(t)}(p) \leq \marpp(p)$;
%  and for the \oplaces $p$ of $\Lambda(\parent{n})$, the chosen value is at least $I_{\lambda(t)}(p)$.\\
%  Moreover, %(2)
%  $\mar \preceq \marp$:
%  for the \noplaces $p$ of $\Lambda(\parent{n})$, we have $\marp(p) = \marpp(p) + \Effect(\lambda(n))(p) = \Lambda(n)(p) \geq \mar(p)$ by choice of $n$ and \mar;
%  and for the \oplaces $p$ of $\Lambda(\parent{n})$, we have $\marp(p) = \marpp(p) + \Effect(\lambda(n))(p) \geq \mar(p)$ by construction of $\marpp$.\\
%  Thus, $\Sigma(n, \mar) = \Sigma(\parent{n}, \marpp) + \lambda(n)$
%  whenever
%  $\alpha(n) = \emptyset \wedge \zeta(n) \neq \emptyset$.
%  %This allows to define $\Sigma(n, \mar)$ recursively up on the branch.
%
%  %We first compute a marking $\marpp \in \downc(\Lambda(n''))$ such that $\lambda(\treepath{n'',n})$ is enabled in $\marpp$, then we show that $\marp$ given by $\marpp\fire{\lambda(\treepath{n'',n})}\marp$ is such that $\mar \preceq \marp$.\\
%  %\[
%  %  \marpp(p) =
%  %  \begin{cases}
%  %    \Lambda(n'')(p)
%  %      &\text{ if } \Lambda(n'')(p) \neq w \\
%  %    \mar(p) - \min(\Effect(\lambda(\treepath{n'',n})), \max\I(\lambda(n_i))
%  %      &\text{ otherwise and if } \Effect(\lambda(\treepath{n'',n})) < 0
%  %  \end{cases}
%
%  %then we compute a marking \marpp
%
%
%  %then we construct $\sigma$ recursively on the nodes of the branch.
%  %The base case is the one treated above, where $\omega$ are first introduced.
%  %Otherwise, one can define a marking $\marpp$ such that $\marpp(p) = \min(\mar(p), \Lambda(\parent{n})(p))$.
%  %And so we have $\Sigma(\mar, n) = \Sigma(\marpp, \parent{n}) + (\lambda(n))$.
%
%  \todo{Formally}
%
%  Finally, let us consider the general case.
%  On the basis of the reflections presented above, we obtain the following method:\\
%  First compute
%
%
%  Finally, let us consider the case where $\Lambda(n)$ may have newly accelerated places as well as others \oplaces.
%  Actually, all the cases studied above are special cases of this one.
%  Here, one can compute $\Sigma(n, \mar)$ by combining the different constructions above:
%  First create a marking
%  \[
%    \marpp(p) = \begin{cases}
%      \Lambda(\parent{n})(p)
%        &\text{ if } p \notin \Omega(\Lambda(\parent{n})) \\
%      \max(\mar(p) - \Effect(\lambda(n))(p), I_{\lambda(t)}(p))
%        &\text{ otherwise}
%    \end{cases}
%  \]
%
%  Then, we fix an order on the places $p_i \in \alpha(n), i \in \{1, 2,…\}$ such that the places accelerated thanks to a node $n_i$ nearer of the root of the tree are the first in $(p_1, p_2...)$.
%  Compute $k_1 = $ \todo{} and for $i \neq 1, k_i = $\todo{}.
%  Then, it is easy to see that $\Sigma(n, \mar) = \Sigma(\parent{n}, \marpp) + \lambda(n) + k_1 \dot \lambda(\treepath{n_1,n}) + k_2 \dot \lambda(\treepath{n_2,n}) + …$
\end{proof}

%%%%%%%%%%%%%

%%%%%%%%%%%%%%% Prove of Karp and Miller algorithm by giving the shortest sequence that is a linear combination of subsequence of the transitions used to create the given branch… this is overkill
%
%To prove that the Karp and Miller Tree $\mathcal{T}$ is a coverability tree of \N, we show
%\begin{enumerate}
%  \item \todo{} that one can construct a sequence from \mari to any marking \mar “covered by the tree” given a node $n$ such that $\mar \in \downc(\lambda(n))$, and
%  \item \todo{} that any marking $\mar \in \post^*(\mari)$ is “covered by at least one node of the tree”.
%\end{enumerate}
%
%\todo{} Finally, we prove that $\mathcal{T}$ is finite and that the algorithm terminates.
%
%Although very different in form, the proofs are based on those stated in \cite{Karp69}.
%
%\begin{lemm}
%  Given an initialized \ac{PN} $\N = \PTm$ and a node $n$ of its Karp and Miller tree $\mathcal{T} = \langle N, B, n_0, \Lambda\rangle$,
%  for any marking $\mar \in \downc(\Lambda(n))$ there exists a sequence of transitions $\sigma \in T^*$ and a marking $\marp$ such that $\mari \fire{\sigma} \marp$ and $\mar \preceq \marp$.
%\end{lemm}
%\begin{proof}
%  We show that there exists a function $\Sigma : \mathbb{N}^{|P|} \times N \mapsto T^* : \mar, n \rightarrow \sigma$ that, given a marking $\mar$ and a node $n$ such that $\mar \in \downc(\Lambda(n))$, gives such a sequence $\sigma$.
%
%  For this purpose, we introduce some notations:
%  \begin{itemize}
%    \item we attach to the Karp and Miller tree $\mathcal{T}$ the mapping $\lambda : N \setminus \{n_0\} \mapsto T$ that gives for all node of the tree (but the root) the transition used to create it at step (2) of the Karp and Miller algorithm.
%
%      By abuse of notation, we will note $\lambda((n_1, n_2, ..., n_m))$
%      %with $n_i, i \in \{1, ..., m\}$ some nodes of $\mathcal{T}$
%      with  $n_i \in N$
%      the sequence $(\lambda(n_2), ..., \lambda(n_m))$.
%    \item for any $n \in N \setminus \{n_0\}$, $\parent{n}$ is the direct ancestor, or \emph{parent}, of $n$ in $\mathcal{T}$, that is, the last but one node in $\treepath{n}$.
%    \item given a sequence of nodes, for any node $n$ of the sequence but the last one, $\child{n}$ is the next node in the sequence.
%    \item \todo{introduce operations on sequences: k.s, s1+s2}
%  \end{itemize}
%
%  Before we look at $\Sigma$, here is one key observation on the Karp and Miller tree:
%  since the Karp and Miller algorithm never remove $\omega$s, we know that $\Omega(\Lambda(n)) \subseteq \Omega(\Lambda(\child{n}))$.
%  Thus we have for any node $n \in N$ three disjoint sets of places whose the union is $P$:
%  \begin{itemize}
%    \item $\eta(n) = P \setminus \Omega(\Lambda(n))$ are the \noplaces of $\Lambda(n)$,
%    \item $\zeta(n) = \Omega(\Lambda(\parent{n}))$ are the \oplaces that were already accelerated in $\Lambda(\parent{n})$, and
%    \item $\alpha(n) = \Omega(\Lambda(n)) \setminus \Omega(\Lambda(\parent{n}))$ are the newly accelerated places.
%  \end{itemize}
%
%
%  Without loss of generality, we assume that $\mari$ does not map any place to $\omega$.
%
%  We now recursively show that $\Sigma(\mar, n)$ exists for all such $\mar, n$ pair.
%
%  If $n$ is the root of the Karp and Miller tree, \mar is covered by $\Lambda(n_0)$ and thus $\Sigma(n, \mar)$ is the empty sequence:
%  \( \Sigma(n, \mar) = () \text{ whenever } n = n_0 \).
%  This is the base case.
%  We now present several simple cases for the induction step in order to easily introduce the general case.
%
%  If $\Lambda(n)$ does not map any place to $\omega$, then,
%  none of $\left\{\Lambda(n') \mid n' \in \treepath{n}\right\}$ do
%  (since the Karp and Miller algorithm never removes $\omega$s)
%  and \mar is covered by $\Lambda(n)$.
%  Thus, the sequence comes directly from $\treepath{n}$.
%  \( \Sigma(n, \mar) = \lambda(\treepath{n}) \text{ whenever } \Omega(\Lambda(n)) = \emptyset \).
%  %Note that the previous case is a special case of this one.
%  In a recursive way, this can be expressed as follows: $\Sigma(n, \mar) = \Sigma(\parent{n}, \Lambda(\parent{n})) + \lambda(n) \text{ whenever } \Omega(\Lambda(n)) = \emptyset$.
%  %\( \Sigma(n, \mar) = \lambda(\treepath{n}) \text{ whenever } \nexists p \in P \text{ s.t. } \Lambda(n)(p) = \omega \)
%  %\[ \Sigma(n, \mar) = \Sigma\big(P(n),\Lambda(P(n))\big) + (\lambda(n)) = \lambda(\treepath{n}) \text{ whenever } \nexists p \in P \text{ s.t. } \Lambda(n)(p) = \omega \]
%
%  If $n$ is the first node of the branch labelled with a marking with places mapped to $\omega$,
%  that is $\zeta(n) = \emptyset \wedge \alpha(n) \neq \emptyset$,
%  we construct $\Sigma(n, \mar) = \sigma$ as follows.
%  (Here are the ideas, we express them more precisely and in a recursive way right after.)\\
%  First, consider the case where there exists exactly one \oplace $p$ in $\Lambda(n)$.
%  This $\omega$ was introduced by $\KMAcc$ thanks to a node $n' \in \treepath{n}, \Lambda(n') \prec \Lambda(n)$.
%  Thus $\lambda(\treepath{n',n})$ is an increasing self covering sequence
%  and
%  there exists some $k \in \mathbb{N}$ and $\marp \in \mathbb{N}^{|P|}$, $\mar \preceq \marp$
%  such that
%  $\sigma = \lambda(\treepath{n'}) + k \cdot \lambda(\treepath{n',n})$ and $\mari \fire{\sigma} \marp$. % with $\mar \preceq \marp$.
%  More precisely, one can choose any $k$ that verifies $k \geq \left\lceil\frac{\mar(p) - \Lambda(n')(p)}{\Effect(\lambda(\treepath{n',n}))}\right\rceil$. %, but lower $k$ may also exists \todo{see notes +1+}.
%  Note that $k > 0$.\\
%  Second, if there exists many \oplaces $p_i$ in $\Lambda(n)$, one can compute $\sigma$ by considering the different $p_i$ one by one:
%  We obtain for $p_1$ the sequence $\sigma_1 = \lambda(\treepath{n_1'}) + k_1 \cdot \lambda(\treepath{n_1',n})$ as above.
%  Let $s_i$ be the sequence of nodes used to obtain $\sigma_i$, that is $s_1 = \treepath{n_1'} + k_1 \cdot \treepath{n_1',n}$.
%  Now observe that
%  the second $\omega$ was introduced thanks to a node $n_2$ that may appear many times in $s_1$ (it does whenever $n_2 \in \treepath{n_1',n}$ and $k_1 > 1$).
%  This recursively extends to any $i \geq 2$.
%  So, the construction of $\sigma_i$ is the same that for $\sigma_1$ except that we use $s_{i-1}$ instead of $\treepath{n}$ and that if $n_i'$ appears many times in $s_{i-1}$, we consider one of its occurrence. Note that the last one should produce the shortest sequence.%whenever there is many $n_i'$ in $\sigma_{i-1}$ we consider the last one of $\sigma_i$.
%  \todo{illustration}
%
%  Let us now express this in a more formal and recursive way.\\
%  Since $\zeta(n) = \emptyset$, the previous case give us $\Sigma(\parent{n}, \Lambda(\parent{n}))$.
%  We denote by $s_0$ the sequence of nodes used to obtain $\Sigma(\parent{n}, \Lambda(\parent{n}))$.
%  Here this sequence is $\treepath{\parent{n}}$, but for the cases that follow, let's keep in mind that $s_0$ is the sequence of nodes used to obtain $\Sigma(\parent{n}, \mathit{previous\_marking})$, whatever $\mathit{previous\_marking}$ is.\\
%  Each place $p_i, i \in \{1, 2, ..., I\}$ of $\alpha(n)$ is accelerated thanks to a node $n_i$.
%  We give an order on this places such that, for $i \leq j$, $\treepath{n_i}$ is shorter or as long as $\treepath{n_j}$.
%  This is to consider the longest self increasing covering sequences first and thus obtain the shortest sequence $\sigma$ \todo{to prove}.\\
%  We compute the sequence of nodes $s$ such that $\sigma = \lambda(s) = \lambda(s_0 + (n) + s_I)$.
%  $s_0 + (n)$ is the ``simple way'' to reach a marking $\downc(\Lambda(n))$ and whose the \noplaces have the values of those of $\Lambda(n)$.
%  We compute shortest $s_I$ to have \marp, $\mar \preceq \marp$:
%  \[
%    s_i =
%    \begin{cases}
%      \left\lceil
%        \frac{\mar(p_i) - \mari(p_i) - \Effect(\lambda(s_0+(n)))(p_i)}
%            {\Effect(\lambda(\treepath{n_i,n}))}
%      \right\rceil
%      \cdot \treepath{n_i,n}
%      &\text{ if } i = 1\\
%      \\
%      \max\left(0,
%        \left\lceil
%          \frac{\mar(p_i) - \mari(p_i) - \Effect(\lambda(s_0+(n)+s_{i-1}))(p_i)}
%              {\Effect(\lambda(\treepath{n_i,n}))}
%        \right\rceil
%      \right)
%      \cdot \treepath{n_i,n}
%      &\text{ if } i \in \{2, ..., I\}\\
%    \end{cases}
%  \]
%
%So we have $\Sigma(n, \mar) = \Sigma(\parent{n}, \Lambda(\parent{n})) + \lambda((n) + s_I)$ whenever $\zeta(n) = \emptyset \wedge \alpha(n) \neq \emptyset$.
%
%  %Since the sequences $s_i$ thus obtained begin with $\treepath{n}$, $\Sigma(n , \mar)$ can be expressed in a recursive form, but it is more complicated than necessary to prove its existence.
%  %\todo{see notes +1+}
%
%
%
%
%  If $\Lambda(n)$ was not accelerated but some of its ancestors was (that is:
%  %$\exists p \in P : \Lambda(n)(p) = \omega$ and $\nexists p' \in P \text{ such that } \Lambda(n)(p') = \omega \wedge \nexists n' \in \treepath{n}, n' \neq n, \Lambda(n')(p') = \omega$.
%  %$\exists p \in P \text{ such that } \Lambda(n)(p) = \omega$ and for all such $p$, $\exists n' \in \treepath{n}, n' \neq n, \Lambda(n')(p) = \omega$)
%  $\alpha(n) = \emptyset \wedge \zeta(n) \neq \emptyset$)
%  then
%  %since the Karp and Miller algorithm never removes $\omega$s,
%  we know that its parent $\parent{n}$ is labelled with a marking ``having all the $\omega$s'' of $\Lambda(n)$:
%  $\Omega(\Lambda(n)) = \Omega(\Lambda(\parent{n}))$.\\
%  One can easily compute the lowest marking $\marpp$ in $\downc(\Lambda(\parent{n}))$ such that $\marpp \fire{\lambda(n)} \marp$ with $\mar \preceq \marpp$:
%  \[
%    \marpp(p) = \begin{cases}
%      \Lambda(\parent{n})(p)
%        &\text{ if } p \notin \Omega(\Lambda(\parent{n})) \\
%      \max(\mar(p) - \Effect(\lambda(n))(p), I_{\lambda(t)}(p))
%        &\text{ otherwise}
%    \end{cases}
%  \]
%
%  %We show that there exists a marking $\marpp \in \downc(\Lambda(\parent{n}))$ such that
%  %(1) $\lambda(n)$ is enabled in $\marpp$
%  %and that
%  %(2) $\marp$ given by $\marpp\fire{\lambda(n)}\marp$ is such that $\mar \preceq \marp$.\\
%  %To define \marpp we use $\Lambda(\parent{n})$ and choose some values for the \oplaces:
%  %We claim that any \marpp as follows holds.
%  %\[
%  %  \marpp(p) = \begin{cases}
%  %    \Lambda(\parent{n})(p)
%  %      &\text{ if } p \notin \Omega(\Lambda(\parent{n})) \\
%  %    c \text{ with } c \geq \max(\mar(p) - \Effect(\lambda(n))(p), I_{\lambda(t)}(p))
%  %      &\text{ otherwise}
%  %  \end{cases}
%  %\]
%  Indeed, %(1)
%  $\lambda(n)$ is enabled in $\marpp$:
%  for the \noplaces $p$ of $\Lambda(\parent{n})$, the Karp and Miller algorithm ensures that $I_{\lambda(t)}(p) \leq \marpp(p)$;
%  and for the \oplaces $p$ of $\Lambda(\parent{n})$, the chosen value is at least $I_{\lambda(t)}(p)$.\\
%  Moreover, %(2)
%  $\mar \preceq \marp$:
%  for the \noplaces $p$ of $\Lambda(\parent{n})$, we have $\marp(p) = \marpp(p) + \Effect(\lambda(n))(p) = \Lambda(n)(p) \geq \mar(p)$ by choice of $n$ and \mar;
%  and for the \oplaces $p$ of $\Lambda(\parent{n})$, we have $\marp(p) = \marpp(p) + \Effect(\lambda(n))(p) \geq \mar(p)$ by construction of $\marpp$.\\
%  Thus, $\Sigma(n, \mar) = \Sigma(\parent{n}, \marpp) + \lambda(n)$
%  whenever
%  $\alpha(n) = \emptyset \wedge \zeta(n) \neq \emptyset$.
%  %This allows to define $\Sigma(n, \mar)$ recursively up on the branch.
%
%  %We first compute a marking $\marpp \in \downc(\Lambda(n''))$ such that $\lambda(\treepath{n'',n})$ is enabled in $\marpp$, then we show that $\marp$ given by $\marpp\fire{\lambda(\treepath{n'',n})}\marp$ is such that $\mar \preceq \marp$.\\
%  %\[
%  %  \marpp(p) =
%  %  \begin{cases}
%  %    \Lambda(n'')(p)
%  %      &\text{ if } \Lambda(n'')(p) \neq w \\
%  %    \mar(p) - \min(\Effect(\lambda(\treepath{n'',n})), \max\I(\lambda(n_i))
%  %      &\text{ otherwise and if } \Effect(\lambda(\treepath{n'',n})) < 0
%  %  \end{cases}
%
%  %then we compute a marking \marpp
%
%
%  %then we construct $\sigma$ recursively on the nodes of the branch.
%  %The base case is the one treated above, where $\omega$ are first introduced.
%  %Otherwise, one can define a marking $\marpp$ such that $\marpp(p) = \min(\mar(p), \Lambda(\parent{n})(p))$.
%  %And so we have $\Sigma(\mar, n) = \Sigma(\marpp, \parent{n}) + (\lambda(n))$.
%
%  \todo{Formally}
%
%  Finally, let us consider the general case.
%  On the basis of the reflections presented above, we obtain the following method:\\
%  First compute
%
%
%  Finally, let us consider the case where $\Lambda(n)$ may have newly accelerated places as well as others \oplaces.
%  Actually, all the cases studied above are special cases of this one.
%  Here, one can compute $\Sigma(n, \mar)$ by combining the different constructions above:
%  First create a marking
%  \[
%    \marpp(p) = \begin{cases}
%      \Lambda(\parent{n})(p)
%        &\text{ if } p \notin \Omega(\Lambda(\parent{n})) \\
%      \max(\mar(p) - \Effect(\lambda(n))(p), I_{\lambda(t)}(p))
%        &\text{ otherwise}
%    \end{cases}
%  \]
%
%  Then, we fix an order on the places $p_i \in \alpha(n), i \in \{1, 2,…\}$ such that the places accelerated thanks to a node $n_i$ nearer of the root of the tree are the first in $(p_1, p_2...)$.
%  Compute $k_1 = $ \todo{} and for $i \neq 1, k_i = $\todo{}.
%  Then, it is easy to see that $\Sigma(n, \mar) = \Sigma(\parent{n}, \marpp) + \lambda(n) + k_1 \dot \lambda(\treepath{n_1,n}) + k_2 \dot \lambda(\treepath{n_2,n}) + …$
%\end{proof}
%
%%%%%%%%%%%%%%%

The Karp and Miller tree has a lot of convenient properties that allow, among other, to answer the coverability problem as well as the simultaneous place unboundedness problem.

\begin{defi}[Simultaneous place unboundedness]
  Let \NPTm be a marked \ac{PN}.
  Given a set of place $Q \subseteq P$, \N is said $Q$-simultaneous unbounded if and only if for any $c \in \mathbb{N}$ there exists \mar such that $\mari \fire* \mar$ and $\forall p \in Q : \mar(p) \geq c$.
\end{defi}

Furthermore, the Karp and Miller algorithm can easily be adapted to some parametric problems \cite{David17}, as we will show in \autoref{sec:preliminaries-ppn}.

However, this tree, although finite, is often much larger than the minimal coverability set, and cannot be constructed in reasonable time.
As a consequence, many improvements were proposed, as well as other algorithms with different approaches.

\subsection{Geeraerts method}
\label{sec:eff}

This is usually called ``an efficient computation method of the coverability set of \acp{PN}''.
It was proposed in \cite{Geeraerts07thesis, Geeraerts07} as another approach to the computation of the coverability set.
It is not based on the Karp and Miller algorithm and is not an alternative to it in the sense that it does not allow to answer the same set of questions than the Karp and Miller tree answers.
However, this technique solves the coverability problem more efficiently in practice.

As in the Karp and Miller algorithm, an acceleration function exploits the strong monotonicity of \acp{PN} to allow termination.
But here, the acceleration of a marking is performed with only one marking as the base (instead of a set of marking).

To choose the base to use, the algorithm works on pair of \omarks.
These pairs allow to record a relationship between the markings.
More precisely, the algorithm constructs a pair of \omarks $(\mar_1, \mar_2)$ only if $\downc(\mar_2) \subseteq \downc(\Post^*(\mar_1))$.

To reduce the size of the set of pairs of \omarks, only the pairs where the difference (as defined below) between $\mar_1$ and $\mar_2$ is maximal are kept.
This will be the purpose of the order $\sqsubseteq$ we will define and it is justified by the intuitive idea that two more distant markings produce larger accelerations.
Therefore, if the algorithm builds a pair $(\mar_1, \mar_2)$, it can forget about any other ($\sqsubseteq$-comparable) pair whose the elements are closer because
\begin{itemize}
  \item by monotonicity, all potential successors of the elements of this pair will be covered by successors of $\mar_1$ or $\mar_2$, and
  \item any acceleration that can be created from this pair is covered by an acceleration one can build from $(\mar_1, \mar_2)$.
\end{itemize}

To describe the algorithm more formally, we will need the following definitions:

Given a pair of \omarks $(\mar_1, \mar_2)$, we define:
\begin{itemize}
  \item $\Postb((\mar_1, \mar_2)) = \{(\mar_1, \marp), (\mar_2, \marp) \mid \marp \in \Post(\mar_2)\}$,
  \item and, with $\mar_1 \prec \mar_2$, $\Accelb(\mar_1, \mar_2) = \{(\mar_2, \KMAcc(\{\mar_1\}, \mar_2))\}$.
    $\Accelb(\mar_1, \mar_2)$ is not defined whenever $\mar_1 \nprec \mar_2$,
\end{itemize}

With $R$ a set of pair of markings, we define:
\begin{itemize}
  \item $\Postb(R) = \bigcup_{(\mar_1, \mar_2) \in R} \Postb((\mar_1, \mar_2))$
  \item $\Accelb(R) = \bigcup_{(\mar_1, \mar_2) \in R}^{\mar_1 \prec \mar_2} \Accelb((\mar_1, \mar_2))$
  \item $\Flatten(R) = \{\mar \mid \exists \marp : (\marp, \mar) \in R\}$
\end{itemize}

The computation of the coverability set of the marked \ac{PN} $\NPTm$ lies on the sequence $\CovSeq(\N) = (V_i)_{i \geq 0}$ of pair of \omarks, where, for all marked \ac{PN} $\N$ we have:
\begin{gather*}
  V_0 = \{(\mari, \mari)\} \text{ and } \\
  \forall i \geq 1 : V_i = V_{i-1} \cup \Postb(V_{i-1}) \cup \Accelb(V_{i-1})
\end{gather*}

One can show that,
first, for all node $n$ of the Karp and Miller tree, there exists a value $k \geq 0$ of $i$ such that $\Lambda(n) \in \Flatten(V_k)$,
second, all the markings produced by $\Postb$ and $\Accelb$ are in the coverability set of \N.
\todo{Indeed...}

These two results lead to the following lemma:
\begin{lemm}[\cite{Geeraerts07}]
  Given a marked \ac{PN} \N such that $\CovSeq(\N) = (V_i)_{i \geq 0}$,
  there exists $k \geq 0$ such that for all $l \in \{0, ..., k-1\}$ we have that $\downc(\Flatten(V_l)) \subset \downc(\Flatten(V_{l+1}))$
  and for all $l \geq k : \downc(\Flatten(V_l)) = \Cover(\N)$.
\end{lemm}

Thus, the algorithm idea is to compute $\CovSeq$ until it stabilizes, \lang{i.e.} to the lowest $l$ such that $\downc(\Flatten(V_l)) = \downc(\Flatten(V_{l-1}))$ and to return $\downc(\Flatten(V_l))$.

To perform it efficiently, one can use a well-chosen order $\sqsubseteq$ on the pair of markings.
This order intents to sort the pairs of markings according to the distance in between, and is used to keep only ``the more distant'' pairs.
Let us denote by $\ominus$ the componentwise difference between two markings and to extend it to \omarks.
Formally, given two \omarks $\mar_1$ and $\mar_2$ on a set of places $P$, $(\mar_1 \ominus \mar_2)(p)$ is defined for all $p \in P$ as:
\[
  \begin{cases}
    \omega & \text{ whenever } \mar_1(p) = \omega \\
    -\omega & \text{ whenever } \mar_2(p) = \omega \text{ and } \mar_1(p) \neq \omega \\
    \mar_1(p) - \mar_2(p) & \text{ otherwise}
  \end{cases}
\]

Now we can define $\sqsubseteq$.
Given two pairs $(\mar_1, \mar_2)$ and $(\marp_1, \marp_2)$ of \omarks over a set of places $P$:
\[
  (\mar_1, \mar_2) \sqsubseteq (\marp_1, \marp_2) \Leftrightarrow
  \begin{cases}
    & \mar_1 \preceq \marp_1 \\
    \wedge & \mar_2 \preceq \marp_2 \\
    \wedge & \forall p \in P : (\mar_2 \ominus \mar_1)(p) \leq (\marp_2 \ominus \marp_1)(p)
  \end{cases}
\]

For a set of pair of \omarks $R$, $\Maxs(R) = \{ r \in R \mid \nexists r' \in R, r \sqsubseteq r'\}$ is the set of highest \omark of $R$ with respect to $\sqsubseteq$.

This order has properties \citep{Geeraerts07} that allows to keep the sets of markings of $\CovSeq$ small.
Thus, one can compute $\Cover(\N)$ of a \ac{PN} \NPTm by computing the sequence $(V_i)_{i \geq 0}$ defined below until $\downc(\Flatten(V_i)) = \downc(\Flatten(V_{i-1}))$.
\begin{gather*}
  V_0 = \{(\mari, \mari)\} \text{ and } \\
  \forall i \geq 1 : V_i = \Maxs(V_{i-1} \cup \Postb(V_{i-1}) \cup \Accelb(V_{i-1}))
\end{gather*}

At the end, we have that $\downc(\Flatten(V_i)) = \Cover(\N)$.

The correction and termination of the algorithm as well as useful properties of $\sqsubseteq$ can be found in \cite{Geeraerts07, Ganty09}.

\subsection{The \ac{EEC} algorithm}
\label{sec:eec}

\ac{EEC}, introduced in \cite{Geeraerts07thesis, Geeraerts06}, is an iterative algorithm that allows, among other, to solve the coverability problem for \ac{PN}.
We present it restricted to this context, but it may be used for a wide range of well-structured transitions systems, which \acp{PN} is part of, because it relies only on the monotonicity, and not on the strong monotonicity, of these models.

The idea is to compute and refine simultaneously an over- and an under-approximation of the covering set of the \ac{PN} until one or the other allows to conclude.

The under-approximation is computed as follows:
We define $(C_i)_{i \geq 0}$ to be the sequence of finite set of markings holding no more than $i$ tokens in each place (plus \mari):
\[
  \forall i \in \mathbb{N} : C_i = \{0, ..., i\}^{|P|} \cup \{\mari\}
\]
At step $i$, the algorithm computes $\Sous(\N, C_i)$ defined as the graph $\langle C_i, \mari, \sousrel \rangle$ which is the transition system induced by the \ac{PN} \N restricted to the markings of $C_i$, \lang{i.e.} $(\mar_1, \mar_2) \in \sousrel$ if, and only if, $\mar_1 \rightarrow \mar_2$.
The under-approximation sought is the set of markings reachable through $\sousrel$ from \mari and is denoted $\R(\Sous(\N, C_i))$.

At step $i$, the algorithm also uses $L_i$ from the sequence $(L_i)_{i \geq 0}$ of finite set of \omarks such that $L_i = \{0, ..., i, \omega \}^{|P|} \cup \{\mari\}$.
That is, $L_i$ contains all the markings with at most $i$ tokens in any place, or $\omega$ (plus \mari).
This set is used to construct the graph $\Sur(\N, C_i)$ defined as the graph $\langle L_i, \mari, \surrel \rangle$ where $(\mar_1, \mar_2) \in \surrel$ if, and only if:
\begin{itemize}
  \item either $\mar_1 \rightarrow \mar_2$,
  \item either $\mar_1 \rightarrow \marp_2, \marp_2 \notin L_i, \marp_2 \preceq \mar_2, \text{ and } \nexists \marpp_2 \in L_i \text{ such that } \marp_2 \prec \marpp_2 \prec \mar_2$.
\end{itemize}
In other words: if $\mar_2 \notin L_i$, it is replaced by the lowest marking of $L_i$ which over-approximate it.
Note that this is an \omark which exists and is unique. \todo{Indeed...}
Then the over-approximation is the set of markings of $L_i$ reachable through $\surrel$ from \mari. It is denoted $\R(\Sur(\N, L_i))$.

We can say that they are under- and over-approximations thanks to the following lemmata:
\begin{lemm}[Under-approximation \cite{Ganty09}]
  For all \ac{PN} \NPTm, for all upward-closed set $U \subseteq \mathbb{N}^{|P|}$, and for all $i \geq 0: \R(\Sous(\N,C_i)) \cap U \neq \emptyset \Rightarrow \Post^*(\mari) \cap U \neq \emptyset$.
\end{lemm}
\begin{lemm}[Over-approximation \cite{Ganty09}]
  For all \ac{PN} \NPTm, for all upward-closed set $U \subseteq \mathbb{N}^{|P|}$, and for all $i \geq 0: \downc(\R(\Sur(\N,L_i))) \cap U = \emptyset \Rightarrow \Post^*(\mari) \cap U = \emptyset$.
\end{lemm}

One can prove that one of the conditions mentioned in the lemmata will eventually happen.
This ensures the termination of the algorithm.

Indeed, let $S$ be the set of markings we want to cover and let $U$ be $\upc(S)$.
If $U$ is reachable, we will eventually get a $C_i$ that contains all the markings of a path from $\mari$ to $U$.
As this path will be present in $\Sous(\N, C_i)$, we will have that $\R(\Sous(\N,C_i)) \cap U \neq \emptyset$.\\
Symmetrically, let $j$ be such that $L_j$ contains the maximal elements of the covering set of \N.
Such a $j$ exists, and we have that $\downc(\R(\Sur(\N,L_j))) = \Cover(\N)$.
Thus, we know that, for a negative instance of the problem, $\downc(\R(\Sur(\N,L_i))) \cap U = \emptyset$ will eventually happen for an $i \leq j$.


\removed{A backward algorithm \citep{Finkel90, Abdulla96}}
%\subsection{A backward algorithm \citep{Finkel90, Abdulla96}}
%
%We will now present an algorithm to solve the coverability problem for a marking \mar of a \ac{PN} $\N = \PTm$.
%
%This algorithm was introduced by Abdulla \lang{et al.} \cite{Abdulla96} for well-structured transition systems, a more general class of models which includes \acp{PN}.
%It is close of the one introduced earlier in \cite{Finkel90}.
%
%Recall the definition for a marking of being coverable.
%\coverability*
%
%For convenience, we will use another equivalent definition.
%
%\begin{defi}[Coverability]
%  Given an initialized \ac{PN} \NPTm and an upward-closed set $U$, $U$ is said coverable if there exists a marking \marp such that $\marp \in U$ and $\mari \fire{*} \marp$.
%\end{defi}
%
%By choosing $\upc(\mar)$ as $U$, these two definitions set out the same instance of the coverability problem.
%With a set of markings considered in the first definition, $U$ may be the union of their upward-closure in the second.
%
%We say it is a backward algorithm in the sense that it is based on the computation of the set $\Pre^*(\mar)$ and answer by checking whether $\mari \in \Pre^*(\mar)$; unlike a forward approach which would have calculated the reachability set and conclude by checking whether \mar was in it. In other words, it computes all the configurations that can reach $U$ in any number of steps.
%
%The calculation is a fixed point algorithm that compute the increasing sequence, for the inclusion relation, of sets of markings: $(R_n)_{n \in \mathbb{N}}$, with $R_0 = U$ and $R_{n+1} = \Pre(R_n) \cup R_n$.
%Thus, $R_n$ is the set of markings from which there exists a sequence of at most $n$ transitions which may be fired and that cover $U$.
%Because, with $U$ an upward-closed set of markings, $\Pre(U)$ is upward-closed too%
%\footnote{This is due to the monotonicity of \acp{PN}, \todo{see for example cite\{someone\}}},
%and because the union of two upward-closed sets is an upward-closed set,
%$R_n$ is upward-closed for all $n$.
%
%\todo{summarize correctness and termination from \cite{Abdulla96}}

% vim: set spell spelllang=en :
